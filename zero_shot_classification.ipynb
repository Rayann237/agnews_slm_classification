{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "The task in this notebook is to evaluate the performance of a small language model for classification.\n",
    "\n",
    "For this work, we will work with AGNews datasets\n",
    "\n",
    "The model will be evaluate in different conditions:\n",
    "- Firstly, we will use to prompt and fine-tune an SLM to see how good it is in classification\n",
    "- Secondly, we will add a prompt to give the task of the SLM and see how it perform with no fine-tuning\n",
    "- Finally, we will use the prompt and the fine-tuning\n",
    "\n",
    "At the end, we will compare the 3 cases and know if the prompt and/or the fine-tune is nessecary for an SLM to be good for a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, ClassLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name1 = \"fancyzhx/ag_news\"\n",
    "\n",
    "agnews_dataset = load_dataset(dataset_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['San Francisco Rules Could Bar Elephants from Zoo Elephants must receive hundreds of times more space to live at San Francisco #39;s zoo or not be kept at the facility, city legislators said on Tuesday in legislation that could effectively bar pachyderms for good.',\n",
       "  ' #39;Bricolage #39; Barroso takes high risk EU gamble By refusing to sack controversial new justice commissioner Rocco Buttiglione, the new Brussels chief may face a protest vote in the European Parliament next Wednesday.',\n",
       "  'Middle East ; Iran Rules Out Complete Nuclear Dismantling  quot;Americans also have no right to raise something like this, quot; he said, adding that Iran had never used its nuclear power program for weapons production.',\n",
       "  'Mistakes hinder Knicks in loss It will be labeled a learning experience, but that won #39;t remove any of the sting. Momentum was lost again Wednesday night as the Knicks blew a lead and lost 94-93 to the Detroit Pistons at Madison Square Garden.',\n",
       "  \"Coping with Contamination in the Search for Life Drilling is a messy business. Drilling fluid is anything but sterile. For most drilling applications, that's no problem. But when astronauts drill for life on Mars, they need to be sure that the bacteria they find really do come from underground.\"],\n",
       " 'label': [3, 0, 0, 1, 3]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agnews_train_val_data = agnews_dataset['train'].train_test_split(test_size=0.2)\n",
    "agnews_train_val_data['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at roneneldan/TinyStories-1M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('roneneldan/TinyStories-1M', num_labels=4)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firtst case : Fine Tune with no prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnews_dataset = DatasetDict(\n",
    "    train=agnews_train_val_data['train'].shuffle(seed=1111),\n",
    "    val=agnews_train_val_data['test'].shuffle(seed=1111),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96000/96000 [01:10<00:00, 1355.86 examples/s]\n",
      "Map: 100%|██████████| 24000/24000 [00:19<00:00, 1247.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([2, 3]),\n",
       " 'input_ids': tensor([[   18,  5849, 28244, 38068, 15792, 47875,  1377,  4942,    78,   220,\n",
       "          12682, 28154,   357, 12637,     8,   532,  7683,  4664, 15792, 47875,\n",
       "           3457,    13,  1222,  2528,    26,    32,   367, 31688,  2625,  4023,\n",
       "           1378,  2503,    13, 24859,   273,    13,   260,  5843,    13,   785,\n",
       "             14, 13295, 25178,    13, 31740,    30,    83, 15799,    28,    34,\n",
       "             13,    45,  2496, 33223, 29522,    14, 24209, 10951,    14, 12853,\n",
       "          22708,     1,     5, 13655,    26,    34,    13,    45,     5,  2528,\n",
       "             26,    14,    32,     5, 13655,    26,   220, 12353,   389,  4305,\n",
       "            262,  1664,    11,   706,   852,  1043, 12387,   220,  4497,   329,\n",
       "            938,  1227,   338,  4137, 16512,   286, 15792, 47875,   338,   220,\n",
       "           2839,  3331,   287,  2869,    11,   257,  1048,  5385,   351,   262,\n",
       "           2300,   531,    13],\n",
       "         [   35,   695, 12043,  6023, 17264,   286, 18460, 22535,   654,  2750,\n",
       "            337, 17139, 12419,  4760,  2538,   220,   220,   220,   360,  7036,\n",
       "           1921,   357,  2969,     8,  1377,  3242,  1586,   257, 19278,  3753,\n",
       "           4122,   284,  8976, 30446, 15503,    12, 11869,   446,  1766,  1539,\n",
       "          23617,  3457,    13,   357,  7206,  3069,     8,  2098,   257,  3016,\n",
       "           1542,  1411,  4391,   287,  2010,  3739,   355,  1913,  4200,   286,\n",
       "          34654,    11,  9597,   290,   407,  1740,  4274,    12, 27003,  8810,\n",
       "            287, 11292,  5939,   986, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agnews_tokenized = agnews_dataset.map(\n",
    "    lambda input: tokenizer(input['text'], padding=True, truncation=True),\n",
    "    batched=True,\n",
    "    batch_size=16\n",
    ")\n",
    "agnews_tokenized = agnews_tokenized.remove_columns([\"text\"])\n",
    "agnews_tokenized = agnews_tokenized.rename_column(\"label\", \"labels\")\n",
    "agnews_tokenized.set_format(\"torch\")\n",
    "agnews_tokenized['train'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "agnews_arguments = TrainingArguments(\n",
    "    output_dir=\"agnews_no_prompt_trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=224\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "agnews_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=agnews_arguments,\n",
    "    train_dataset=agnews_tokenized['train'],\n",
    "    eval_dataset=agnews_tokenized['val'], # change to test when you do your final evaluation!\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingCallback(TrainerCallback):\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "    # will call on_log on each logging step, specified by TrainerArguement. (i.e TrainerArguement.logginng_step)\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(json.dumps(logs) + \"\\n\")\n",
    "    # def on_epoch(...)\n",
    "\n",
    "\n",
    "agnews_trainer.add_callback(EarlyStoppingCallback())\n",
    "agnews_trainer.add_callback(LoggingCallback(\"agnews_no_prompt_trainer/log.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 59:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.417415</td>\n",
       "      <td>0.849583</td>\n",
       "      <td>0.853389</td>\n",
       "      <td>0.849123</td>\n",
       "      <td>0.847334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.310740</td>\n",
       "      <td>0.892875</td>\n",
       "      <td>0.896142</td>\n",
       "      <td>0.892845</td>\n",
       "      <td>0.892331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.283598</td>\n",
       "      <td>0.903875</td>\n",
       "      <td>0.904640</td>\n",
       "      <td>0.903745</td>\n",
       "      <td>0.903966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.271825</td>\n",
       "      <td>0.908792</td>\n",
       "      <td>0.908717</td>\n",
       "      <td>0.908636</td>\n",
       "      <td>0.908627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.273746</td>\n",
       "      <td>0.911167</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.910945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.3053658576965332, metrics={'train_runtime': 3552.5833, 'train_samples_per_second': 135.113, 'train_steps_per_second': 2.815, 'train_loss': 0.3053658576965332, 'epoch': 5.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "agnews_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Case : Add a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at roneneldan/TinyStories-1M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('roneneldan/TinyStories-1M', num_labels=4)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prompt(input):\n",
    "  prompt= f\" Answer by 0 (world), 1 (sports), 2 (business) or 3 (sci/tech). The article \\\"{input['text']}\\\" is about \"\n",
    "  return {\n",
    "      'text': prompt,\n",
    "      'label': input['label']\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96000/96000 [00:14<00:00, 6443.52 examples/s]\n",
      "Map: 100%|██████████| 24000/24000 [00:03<00:00, 7005.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "agnews_dataset = DatasetDict(\n",
    "    train=agnews_train_val_data['train'].shuffle(seed=1111).map(add_prompt),\n",
    "    val=agnews_train_val_data['test'].shuffle(seed=1111).map(add_prompt),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96000/96000 [01:17<00:00, 1235.34 examples/s]\n",
      "Map: 100%|██████████| 24000/24000 [00:18<00:00, 1275.21 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([2, 3]),\n",
       " 'input_ids': tensor([[23998,   416,   657,   357,  6894,   828,   352,   357, 32945,   828,\n",
       "            362,   357, 22680,     8,   393,   513,   357, 36216,    14, 13670,\n",
       "            737,   383,  2708,   366,    18,  5849, 28244, 38068, 15792, 47875,\n",
       "           1377,  4942,    78,   220, 12682, 28154,   357, 12637,     8,   532,\n",
       "           7683,  4664, 15792, 47875,  3457,    13,  1222,  2528,    26,    32,\n",
       "            367, 31688,  2625,  4023,  1378,  2503,    13, 24859,   273,    13,\n",
       "            260,  5843,    13,   785,    14, 13295, 25178,    13, 31740,    30,\n",
       "             83, 15799,    28,    34,    13,    45,  2496, 33223, 29522,    14,\n",
       "          24209, 10951,    14, 12853, 22708,     1,     5, 13655,    26,    34,\n",
       "             13,    45,     5,  2528,    26,    14,    32,     5, 13655,    26,\n",
       "            220, 12353,   389,  4305,   262,  1664,    11,   706,   852,  1043,\n",
       "          12387,   220,  4497,   329,   938,  1227,   338,  4137, 16512,   286,\n",
       "          15792, 47875,   338,   220,  2839,  3331,   287,  2869,    11,   257,\n",
       "           1048,  5385,   351,   262,  2300,   531,   526,   318,   546,   220],\n",
       "         [23998,   416,   657,   357,  6894,   828,   352,   357, 32945,   828,\n",
       "            362,   357, 22680,     8,   393,   513,   357, 36216,    14, 13670,\n",
       "            737,   383,  2708,   366,    35,   695, 12043,  6023, 17264,   286,\n",
       "          18460, 22535,   654,  2750,   337, 17139, 12419,  4760,  2538,   220,\n",
       "            220,   220,   360,  7036,  1921,   357,  2969,     8,  1377,  3242,\n",
       "           1586,   257, 19278,  3753,  4122,   284,  8976, 30446, 15503,    12,\n",
       "          11869,   446,  1766,  1539, 23617,  3457,    13,   357,  7206,  3069,\n",
       "              8,  2098,   257,  3016,  1542,  1411,  4391,   287,  2010,  3739,\n",
       "            355,  1913,  4200,   286, 34654,    11,  9597,   290,   407,  1740,\n",
       "           4274,    12, 27003,  8810,   287, 11292,  5939,  9313,   318,   546,\n",
       "            220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agnews_tokenized = agnews_dataset.map(\n",
    "    lambda input: tokenizer(input['text'], padding=True, truncation=True),\n",
    "    batched=True,\n",
    "    batch_size=16\n",
    ")\n",
    "agnews_tokenized = agnews_tokenized.remove_columns([\"text\"])\n",
    "agnews_tokenized = agnews_tokenized.rename_column(\"label\", \"labels\")\n",
    "agnews_tokenized.set_format(\"torch\")\n",
    "agnews_tokenized['train'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_training_args = TrainingArguments(\n",
    "    output_dir=\"agnews_prompt_no_train\",\n",
    "    eval_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "agnews_no_train = Trainer(\n",
    "    model=model,\n",
    "    args=no_training_args,\n",
    "    train_dataset=agnews_tokenized['train'],\n",
    "    eval_dataset=agnews_tokenized['val'], # change to test when you do your final evaluation!\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.447458028793335,\n",
       " 'eval_accuracy': 0.24579166666666666,\n",
       " 'eval_precision': 0.11694861946107933,\n",
       " 'eval_recall': 0.24771749298938822,\n",
       " 'eval_f1_score': 0.15288915380787896,\n",
       " 'eval_runtime': 175.4355,\n",
       " 'eval_samples_per_second': 136.802,\n",
       " 'eval_steps_per_second': 5.7}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = agnews_no_train.evaluate()\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Case : Add a prompt and Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at roneneldan/TinyStories-1M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('roneneldan/TinyStories-1M', num_labels=4)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnews_arguments = TrainingArguments(\n",
    "    output_dir=\"agnews_prompt_trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=224\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "agnews_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=agnews_arguments,\n",
    "    train_dataset=agnews_tokenized['train'],\n",
    "    eval_dataset=agnews_tokenized['val'], # change to test when you do your final evaluation!\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnews_trainer.add_callback(EarlyStoppingCallback())\n",
    "agnews_trainer.add_callback(LoggingCallback(\"agnews_prompt_trainer/log.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 59:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.398094</td>\n",
       "      <td>0.860458</td>\n",
       "      <td>0.862527</td>\n",
       "      <td>0.859912</td>\n",
       "      <td>0.858525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.313359</td>\n",
       "      <td>0.891167</td>\n",
       "      <td>0.895912</td>\n",
       "      <td>0.891236</td>\n",
       "      <td>0.891142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>0.287570</td>\n",
       "      <td>0.902625</td>\n",
       "      <td>0.905031</td>\n",
       "      <td>0.902607</td>\n",
       "      <td>0.902889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.278183</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>0.907623</td>\n",
       "      <td>0.907187</td>\n",
       "      <td>0.907373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.276344</td>\n",
       "      <td>0.909875</td>\n",
       "      <td>0.909610</td>\n",
       "      <td>0.909693</td>\n",
       "      <td>0.909640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:34: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/infres/rtchokog-23/slm_classification/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.303584033203125, metrics={'train_runtime': 3542.93, 'train_samples_per_second': 135.481, 'train_steps_per_second': 2.823, 'train_loss': 0.303584033203125, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "agnews_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can notice that fine-tuning is neccessary for a good classification:\n",
    "- F1-score = 0.91 when the model is fine-tune vs 0.15 when not\n",
    "- With a prompt, the F1-score at the first epoch is higher but the result still close so it's difficult to conclude if a good prompting could lead to a better classification",
    "- Looking at the training loss, we can notice a better convergence with a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
